This is a document outlining what we might wish to answer in a usage report, written in the form of user stories.
Questions range from able to be easily answered **with data from the platform** to not answerable at all.
Topics that are currently not feasible but important can lead to thinking about what/how other data can be collected.

Importance:
- ⭐⭐⭐ / High 
- ⭐⭐ / Medium
- ⭐ / Low

Feasibility
- 🟢 / Doable with platform data
- 🟡 / Painfully doable with platform data
- 🔴 / Not doable with platform data

A funder, I would like to know...

#### How many studies changed status from "Under Embargo" to "Partially Available"/"Available" between the beginning to the end of the year (or whatever the report period may be). ⭐⭐⭐ | 🟢 
- This would 1) give indication that data is being released on time and 2) help set up expectations for what downloads might look like based on releases.

#### How long does it take for others to use the data once there is data released (for those projects that do see use). ⭐⭐ | 🟡  
- Help understand the range of timelines on "returns" -- do researchers jump on the data within a month, or a year? 
- Date of first download - Date status change.
- "Data release" dates are not officially (and sometimes not accurately) tracked, so only have snapshots of the study table. 

#### Which of the projects in my portfolio have seen the most usage in terms of absolute downloads? ⭐⭐⭐ | 🟢 
- Top 20% of projects with the most impact/interest.

#### What proportion of projects in my portfolio have seen any usage (Team A projects) vs. not (Team B projects)? ⭐⭐⭐ | 🟢 
- Example: 40% use vs. 60% no use.

#### Are there any differences in Team A projects vs Team B projects? ⭐⭐ | 🟡 
- Size of project (total number of files)?
- Age? (Since it takes time to be aware of projects.)

#### What is the summary of usage in terms of absolute file downloads? In terms of unique platform users? ⭐⭐⭐ | 🟢

#### What is the summary of usage in terms of secondary citations? ⭐⭐⭐ | 🔴 
- This requires curation *outside* of the platform. Some platforms such as dbGaP can require that any publications using the data must be documented, in which case this information becomes part of the platform.

#### What has been the trend in interest/downloads over this period? ⭐⭐⭐ | 🟢

#### What is the type breakdown of data being used? ⭐⭐⭐ | 🟢

#### How do data users learn about the data -- directly through the portal, the publication, newsletter/social media, word-of-mouth, something else? ⭐⭐ | 🔴 

#### How is the data used -- e.g. for NF-specific research, NF-related, or NF-unrelated? ⭐⭐⭐ | 🟡
- Relevant only for funders that allow relatively open use -- i.e. for GFF it *must* already be NF-specific research.
- This would *only* be available for data that requires a data use statement, and would need manual review to categorize the usage.

#### What is the demographics of my data users? ⭐⭐ | 🔴
- Grad students, post-docs, PIs, academic, industry? Where are they from?
- This may be somewhat answerable if there are only a handful of profiles to manually review, and they're *all* filled out, but the platform needs to require this information as part of the standard profile for this to be truly feasible.
- Since platform data is lacking, another method is more _indirectly_ though surveys. 

#### How does my reach compare with other funding agencies (e.g. NTAP  vs CTF)? ⭐⭐ | 🟢
- Data are on same platform and should be pretty much comparable.
- Account for different number of projects/types of projects. 
- Compare projects unique to the funding agency (i.e. ignore projects with collaborative funding).

#### What correlates with data use? The funding amount of the project, quantity of data available (which should already depend on the funding), numbers of reads for the related publication, type of data, extent of social media engagement, etc.? (Similar to but larger in scope compared to one of the above.) ⭐⭐⭐ | 🔴
- Most of this data is outside the scope/a big effort to get.


