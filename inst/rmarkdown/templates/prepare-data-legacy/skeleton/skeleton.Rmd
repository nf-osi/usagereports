---
title: "Prepare data (legacy datawarehouse)"
author: "Your Name"
date: "YYYY-MM"
output: output_format
---

```{r setup, include=FALSE}

library(data.table)
library(nfportalutils)
library(googleAnalyticsR)
library(usagereports) 

syn_login()
```

## Query portal studies 

This queries data from the warehouse snapshot database -- it can take at least several hours for a funding agency such as NTAP. 

To connect to your warehouse snapshot, create a `config.yml` with the snapshot parameters from the [build](http://build-system-dw.sagebase.org:8080/login?from=%2Fjob%2FLaunch%2520warehouse%2520snapshot%2F).
If an older `config.yml` does not exist to reuse with updated parameters, use the helper `dw_config` to write out one for you to fill in.
The snapshot name and credentials should match what was specified during the build.
Also make sure that you are on the Sage VPN in order to connect to your snapshot.

### Connect
```{r}
con <- usagereports::connect_to_dw(config_file = "config.yml")
```

### Query data

Start and end dates of the query should be specified. 
It is suggested to use **quarterly intervals**, which seems to be faster than pulling data in one six-month batch. It also works better for any unexpected disconnections. 
Thus, there are two blocks for querying data.
```{r}

start_date <- "2023-03-01"
end_date <- "2023-06-01"

query_data_by_funding_agency(con = con, 
                             start_date = start_date, 
                             end_date = end_date, 
                             disconnect = FALSE)
```


```{r}

start_date <- "2023-06-01"
end_date <- "2023-09-01"

query_data_by_funding_agency(con = con, 
                             start_date = start_date, 
                             end_date = end_date, 
                             disconnect = FALSE)
```

### Compile data

The raw query data can now be consolidated. 
The consolidated data is the intermediate data result to archive and pass to downstream integration/plotting functions.

During this transformation, user ids are masked.
Download the [encryption key](https://www.synapse.org/#!Synapse:syn39770191/files/). 
The `codes.csv` can be committed to the git repo. Here the path expects that it's several levels up. 
It is the encrypted mapping of real user ids to masked user ids and should be updated and re-committed to the git repo with each batch.


```{r}


```




